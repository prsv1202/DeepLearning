{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnnHBPBRnK6X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "pd.options.display.max_rows = None\n",
        "pd.options.display.max_columns = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data frame\n",
        "df = pd.read_csv('/content/Churn_Modelling.csv', delimiter=',')\n",
        "df"
      ],
      "metadata": {
        "id": "YwWiq88MnzFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "dHxksx2MogmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "mufBS_fyonzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1)\n"
      ],
      "metadata": {
        "id": "OUWFtVRiopag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "FW_FZvGoorTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check variable data types\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "2ERgX2sJosuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = 'Exited', 'Retained'\n",
        "sizes = [df.Exited[df['Exited']==1].count(), df.Exited[df['Exited']==0].count()]\n",
        "explode = (0, 0.1)\n",
        "fig1, ax1 = plt.subplots(figsize=(10, 8))\n",
        "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax1.axis('equal')\n",
        "plt.title(\"Proportion of customer churned and retained\", size = 20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z0poSZ23ovXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # We first review the 'Status' relation with categorical variables\n",
        "    fig, axarr = plt.subplots(2, 2, figsize=(20, 12))\n",
        "    sns.countplot(x='Geography', hue = 'Exited',data = df, ax=axarr[0][0])\n",
        "    sns.countplot(x='Gender', hue = 'Exited',data = df, ax=axarr[0][1])\n",
        "    sns.countplot(x='HasCrCard', hue = 'Exited',data = df, ax=axarr[1][0])\n",
        "    sns.countplot(x='IsActiveMember', hue = 'Exited',data = df, ax=axarr[1][1])"
      ],
      "metadata": {
        "id": "pJYV7hyUoxwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Relations based on the continuous data attributes\n",
        "    fig, axarr = plt.subplots(3, 2, figsize=(20, 12))\n",
        "    sns.boxplot(y='CreditScore',x = 'Exited', hue = 'Exited',data = df, ax=axarr[0][0])\n",
        "    sns.boxplot(y='Age',x = 'Exited', hue = 'Exited',data = df , ax=axarr[0][1])\n",
        "    sns.boxplot(y='Tenure',x = 'Exited', hue = 'Exited',data = df, ax=axarr[1][0])\n",
        "    sns.boxplot(y='Balance',x = 'Exited', hue = 'Exited',data = df, ax=axarr[1][1])\n",
        "    sns.boxplot(y='NumOfProducts',x = 'Exited', hue = 'Exited',data = df, ax=axarr[2][0])\n",
        "    sns.boxplot(y='EstimatedSalary',x = 'Exited', hue = 'Exited',data = df, ax=axarr[2][1])"
      ],
      "metadata": {
        "id": "2QK3kGoXo0G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Train, test data\n",
        "df_train = df.sample(frac=0.8,random_state=200)\n",
        "df_test = df.drop(df_train.index)\n",
        "print(len(df_train))\n",
        "print(len(df_test))"
      ],
      "metadata": {
        "id": "yR3_PcMdo2x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['BalanceSalaryRatio'] = df_train.Balance/df_train.EstimatedSalary\n",
        "sns.boxplot(y='BalanceSalaryRatio',x = 'Exited', hue = 'Exited',data = df_train)\n",
        "plt.ylim(-1, 5)"
      ],
      "metadata": {
        "id": "9T1-hsmJo4_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given that tenure is a 'function' of age, we introduce a variable aiming to standardize tenure over age:\n",
        "df_train['TenureByAge'] = df_train.Tenure/(df_train.Age)\n",
        "sns.boxplot(y='TenureByAge',x = 'Exited', hue = 'Exited',data = df_train)\n",
        "plt.ylim(-1, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X9HSnKyLo6fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Lastly we introduce a variable to capture credit score given age to take into account credit behaviour visavis adult life\n",
        ":-)'''\n",
        "df_train['CreditScoreGivenAge'] = df_train.CreditScore/(df_train.Age)"
      ],
      "metadata": {
        "id": "fjFgEs0Oo8ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resulting Data Frame\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "FVzciIV3o-cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arrange columns by data type for easier manipulation\n",
        "continuous_vars = ['CreditScore',  'Age', 'Tenure', 'Balance','NumOfProducts', 'EstimatedSalary', 'BalanceSalaryRatio',\n",
        "                   'TenureByAge','CreditScoreGivenAge']\n",
        "cat_vars = ['HasCrCard', 'IsActiveMember','Geography', 'Gender']\n",
        "df_train = df_train[['Exited'] + continuous_vars + cat_vars]\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "hxZUFqRgpAZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''For the one hot variables, we change 0 to -1 so that the models can capture a negative relation \n",
        "where the attribute in inapplicable instead of 0'''\n",
        "df_train.loc[df_train.HasCrCard == 0, 'HasCrCard'] = -1\n",
        "df_train.loc[df_train.IsActiveMember == 0, 'IsActiveMember'] = -1\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "C4leG0axpCAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode the categorical variables\n",
        "lst = ['Geography', 'Gender']\n",
        "remove = list()\n",
        "for i in lst:\n",
        "    if (df_train[i].dtype == np.str or df_train[i].dtype == np.object):\n",
        "        for j in df_train[i].unique():\n",
        "            df_train[i+'_'+j] = np.where(df_train[i] == j,1,-1)\n",
        "        remove.append(i)\n",
        "df_train = df_train.drop(remove, axis=1)\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "ZdHtcTUJpDzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# minMax scaling the continuous variables\n",
        "minVec = df_train[continuous_vars].min().copy()\n",
        "maxVec = df_train[continuous_vars].max().copy()\n",
        "df_train[continuous_vars] = (df_train[continuous_vars]-minVec)/(maxVec-minVec)\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "1SUWB2EhpGBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data prep pipeline for test data\n",
        "def DfPrepPipeline(df_predict,df_train_Cols,minVec,maxVec):\n",
        "    # Add new features\n",
        "    df_predict['BalanceSalaryRatio'] = df_predict.Balance/df_predict.EstimatedSalary\n",
        "    df_predict['TenureByAge'] = df_predict.Tenure/(df_predict.Age - 18)\n",
        "    df_predict['CreditScoreGivenAge'] = df_predict.CreditScore/(df_predict.Age - 18)\n",
        "    # Reorder the columns\n",
        "    continuous_vars = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary','BalanceSalaryRatio',\n",
        "                   'TenureByAge','CreditScoreGivenAge']\n",
        "    cat_vars = ['HasCrCard','IsActiveMember',\"Geography\", \"Gender\"] \n",
        "    df_predict = df_predict[['Exited'] + continuous_vars + cat_vars]\n",
        "    # Change the 0 in categorical variables to -1\n",
        "    df_predict.loc[df_predict.HasCrCard == 0, 'HasCrCard'] = -1\n",
        "    df_predict.loc[df_predict.IsActiveMember == 0, 'IsActiveMember'] = -1\n",
        "    # One hot encode the categorical variables\n",
        "    lst = [\"Geography\", \"Gender\"]\n",
        "    remove = list()\n",
        "    for i in lst:\n",
        "        for j in df_predict[i].unique():\n",
        "            df_predict[i+'_'+j] = np.where(df_predict[i] == j,1,-1)\n",
        "        remove.append(i)\n",
        "    df_predict = df_predict.drop(remove, axis=1)\n",
        "    # Ensure that all one hot encoded variables that appear in the train data appear in the subsequent data\n",
        "    L = list(set(df_train_Cols) - set(df_predict.columns))\n",
        "    for l in L:\n",
        "        df_predict[str(l)] = -1        \n",
        "    # MinMax scaling coontinuous variables based on min and max from the train data\n",
        "    df_predict[continuous_vars] = (df_predict[continuous_vars]-minVec)/(maxVec-minVec)\n",
        "    # Ensure that The variables are ordered in the same way as was ordered in the train set\n",
        "    df_predict = df_predict[df_train_Cols]\n",
        "    return df_predict"
      ],
      "metadata": {
        "id": "akhrOk6HpHsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support functions\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Fit models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Scoring functions\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve"
      ],
      "metadata": {
        "id": "f1z--3GipMI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to give best model score and parameters\n",
        "def best_model(model):\n",
        "    print(model.best_score_)    \n",
        "    print(model.best_params_)\n",
        "    print(model.best_estimator_)\n",
        "def get_auc_scores(y_actual, method,method2):\n",
        "    auc_score = roc_auc_score(y_actual, method); \n",
        "    fpr_df, tpr_df, _ = roc_curve(y_actual, method2); \n",
        "    return (auc_score, fpr_df, tpr_df)"
      ],
      "metadata": {
        "id": "AvOyFwfGpOv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit primal logistic regression\n",
        "param_grid = {'C': [0.1,0.5,1,10,50,100], 'max_iter': [250], 'fit_intercept':[True],'intercept_scaling':[1],\n",
        "              'penalty':['l2'], 'tol':[0.00001,0.0001,0.000001]}\n",
        "log_primal_Grid = GridSearchCV(LogisticRegression(solver='lbfgs'),param_grid, cv=10, refit=True, verbose=0)\n",
        "log_primal_Grid.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)\n",
        "best_model(log_primal_Grid)"
      ],
      "metadata": {
        "id": "GYr_a6AupQha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit logistic regression with degree 2 polynomial kernel\n",
        "param_grid = {'C': [0.1,10,50], 'max_iter': [300,500], 'fit_intercept':[True],'intercept_scaling':[1],'penalty':['l2'],\n",
        "              'tol':[0.0001,0.000001]}\n",
        "poly2 = PolynomialFeatures(degree=2)\n",
        "df_train_pol2 = poly2.fit_transform(df_train.loc[:, df_train.columns != 'Exited'])\n",
        "log_pol2_Grid = GridSearchCV(LogisticRegression(solver = 'liblinear'),param_grid, cv=5, refit=True, verbose=0)\n",
        "log_pol2_Grid.fit(df_train_pol2,df_train.Exited)\n",
        "best_model(log_pol2_Grid)"
      ],
      "metadata": {
        "id": "bceiOvTlpSHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit SVM with RBF Kernel\n",
        "param_grid = {'C': [0.5,100,150], 'gamma': [0.1,0.01,0.001],'probability':[True],'kernel': ['rbf']}\n",
        "SVM_grid = GridSearchCV(SVC(), param_grid, cv=3, refit=True, verbose=0)\n",
        "SVM_grid.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)\n",
        "best_model(SVM_grid)"
      ],
      "metadata": {
        "id": "J8mP9woFpUG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit SVM with pol kernel\n",
        "param_grid = {'C': [0.5,1,10,50,100], 'gamma': [0.1,0.01,0.001],'probability':[True],'kernel': ['poly'],'degree':[2,3] }\n",
        "SVM_grid = GridSearchCV(SVC(), param_grid, cv=3, refit=True, verbose=0)\n",
        "SVM_grid.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)\n",
        "best_model(SVM_grid)"
      ],
      "metadata": {
        "id": "8UOMMcbTpWE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit random forest classifier\n",
        "param_grid = {'max_depth': [3, 5, 6, 7, 8], 'max_features': [2,4,6,7,8,9],'n_estimators':[50,100],'min_samples_split': [3, 5, 6, 7]}\n",
        "RanFor_grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, refit=True, verbose=0)\n",
        "RanFor_grid.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)\n",
        "best_model(RanFor_grid)"
      ],
      "metadata": {
        "id": "kPnQyqOxpXyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Extreme Gradient boosting classifier\n",
        "param_grid = {'max_depth': [5,6,7,8], 'gamma': [0.01,0.001,0.001],'min_child_weight':[1,5,10], 'learning_rate': [0.05,0.1, 0.2, 0.3], 'n_estimators':[5,10,20,100]}\n",
        "xgb_grid = GridSearchCV(XGBClassifier(), param_grid, cv=5, refit=True, verbose=0)\n",
        "xgb_grid.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)\n",
        "best_model(xgb_grid)"
      ],
      "metadata": {
        "id": "z_51zlmBpZXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit primal logistic regression\n",
        "log_primal = LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, max_iter=250, multi_class='warn',n_jobs=None, \n",
        "                                penalty='l2', random_state=None, solver='lbfgs',tol=1e-05, verbose=0, warm_start=False)\n",
        "log_primal.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)"
      ],
      "metadata": {
        "id": "g3NzypzwpbPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit logistic regression with pol 2 kernel\n",
        "poly2 = PolynomialFeatures(degree=2)\n",
        "df_train_pol2 = poly2.fit_transform(df_train.loc[:, df_train.columns != 'Exited'])\n",
        "log_pol2 = LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,intercept_scaling=1, max_iter=300, multi_class='warn', n_jobs=None, \n",
        "                              penalty='l2', random_state=None, solver='liblinear',tol=0.0001, verbose=0, warm_start=False)\n",
        "log_pol2.fit(df_train_pol2,df_train.Exited)"
      ],
      "metadata": {
        "id": "lGPV9IvKpc_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit SVM with RBF Kernel\n",
        "SVM_RBF = SVC(C=100, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf', max_iter=-1, probability=True, \n",
        "              random_state=None, shrinking=True,tol=0.001, verbose=False)\n",
        "SVM_RBF.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)"
      ],
      "metadata": {
        "id": "rFvc5UFYpe7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit SVM with Pol Kernel\n",
        "SVM_POL = SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,  decision_function_shape='ovr', degree=2, gamma=0.1, kernel='poly',  max_iter=-1,\n",
        "              probability=True, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
        "SVM_POL.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)"
      ],
      "metadata": {
        "id": "Iw5ZPOkkpggL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Random Forest classifier\n",
        "RF = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',max_depth=8, max_features=6, max_leaf_nodes=None,min_impurity_decrease=0.0,\n",
        "                            min_impurity_split=None,min_samples_leaf=1, min_samples_split=3,min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
        "                            oob_score=False, random_state=None, verbose=0,warm_start=False)\n",
        "RF.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)"
      ],
      "metadata": {
        "id": "nHonaGR4piTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Extreme Gradient Boost Classifier\n",
        "XGB = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,colsample_bytree=1, gamma=0.01, learning_rate=0.1, max_delta_step=0,max_depth=7,\n",
        "                    min_child_weight=5, missing=None, n_estimators=20,n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,reg_alpha=0, \n",
        "                    reg_lambda=1, scale_pos_weight=1, seed=None, silent=True, subsample=1)\n",
        "XGB.fit(df_train.loc[:, df_train.columns != 'Exited'],df_train.Exited)"
      ],
      "metadata": {
        "id": "IQuS5Z_lpkCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(df_train.Exited, log_primal.predict(df_train.loc[:, df_train.columns != 'Exited'])))"
      ],
      "metadata": {
        "id": "PC2XM_ZRqAVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(df_train.Exited,  log_pol2.predict(df_train_pol2)))"
      ],
      "metadata": {
        "id": "uskwMZAlqEAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(df_train.Exited,  SVM_RBF.predict(df_train.loc[:, df_train.columns != 'Exited'])))"
      ],
      "metadata": {
        "id": "nY_44oO2qHLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(df_train.Exited,  SVM_POL.predict(df_train.loc[:, df_train.columns != 'Exited'])))"
      ],
      "metadata": {
        "id": "Nb_fQLJYqHcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(df_train.Exited,  RF.predict(df_train.loc[:, df_train.columns != 'Exited'])))"
      ],
      "metadata": {
        "id": "K-Yw-naMqHjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(df_train.Exited,  XGB.predict(df_train.loc[:, df_train.columns != 'Exited'])))"
      ],
      "metadata": {
        "id": "RsrT-yYaqNJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_train.Exited\n",
        "X = df_train.loc[:, df_train.columns != 'Exited']\n",
        "X_pol2 = df_train_pol2\n",
        "auc_log_primal, fpr_log_primal, tpr_log_primal = get_auc_scores(y, log_primal.predict(X),log_primal.predict_proba(X)[:,1])\n",
        "auc_log_pol2, fpr_log_pol2, tpr_log_pol2 = get_auc_scores(y, log_pol2.predict(X_pol2),log_pol2.predict_proba(X_pol2)[:,1])\n",
        "auc_SVM_RBF, fpr_SVM_RBF, tpr_SVM_RBF = get_auc_scores(y, SVM_RBF.predict(X),SVM_RBF.predict_proba(X)[:,1])\n",
        "auc_SVM_POL, fpr_SVM_POL, tpr_SVM_POL = get_auc_scores(y, SVM_POL.predict(X),SVM_POL.predict_proba(X)[:,1])\n",
        "auc_RF, fpr_RF, tpr_RF = get_auc_scores(y, RF.predict(X),RF.predict_proba(X)[:,1])\n",
        "auc_XGB, fpr_XGB, tpr_XGB = get_auc_scores(y, XGB.predict(X),XGB.predict_proba(X)[:,1])"
      ],
      "metadata": {
        "id": "o_yLvx7QqOpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,6), linewidth= 1)\n",
        "plt.plot(fpr_log_primal, tpr_log_primal, label = 'log primal Score: ' + str(round(auc_log_primal, 5)))\n",
        "plt.plot(fpr_log_pol2, tpr_log_pol2, label = 'log pol2 score: ' + str(round(auc_log_pol2, 5)))\n",
        "plt.plot(fpr_SVM_RBF, tpr_SVM_RBF, label = 'SVM RBF Score: ' + str(round(auc_SVM_RBF, 5)))\n",
        "plt.plot(fpr_SVM_POL, tpr_SVM_POL, label = 'SVM POL Score: ' + str(round(auc_SVM_POL, 5)))\n",
        "plt.plot(fpr_RF, tpr_RF, label = 'RF score: ' + str(round(auc_RF, 5)))\n",
        "plt.plot(fpr_XGB, tpr_XGB, label = 'XGB score: ' + str(round(auc_XGB, 5)))\n",
        "plt.plot([0,1], [0,1], 'k--', label = 'Random: 0.5')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='best')\n",
        "#plt.savefig('roc_results_ratios.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KDeDEGoAqOwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the data transformation for test data\n",
        "df_test = DfPrepPipeline(df_test,df_train.columns,minVec,maxVec)\n",
        "df_test = df_test.mask(np.isinf(df_test))\n",
        "df_test = df_test.dropna()\n",
        "df_test.shape"
      ],
      "metadata": {
        "id": "1h36iilzqUxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(df_test.Exited,  RF.predict(df_test.loc[:, df_test.columns != 'Exited'])))"
      ],
      "metadata": {
        "id": "oKmtTaunqXgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_RF_test, fpr_RF_test, tpr_RF_test = get_auc_scores(df_test.Exited, RF.predict(df_test.loc[:, df_test.columns != 'Exited']),\n",
        "                                                       RF.predict_proba(df_test.loc[:, df_test.columns != 'Exited'])[:,1])\n",
        "plt.figure(figsize = (12,6), linewidth= 1)\n",
        "plt.plot(fpr_RF_test, tpr_RF_test, label = 'RF score: ' + str(round(auc_RF_test, 5)))\n",
        "plt.plot([0,1], [0,1], 'k--', label = 'Random: 0.5')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='best')\n",
        "#plt.savefig('roc_results_ratios.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U6PPbgAnqXu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vOoI19uhqAfh"
      }
    }
  ]
}